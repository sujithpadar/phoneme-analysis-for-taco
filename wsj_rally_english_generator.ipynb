{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Notebook to generate 10,20, 50 Finnish phoneme representation for each English words in the game data.\n",
    "Created from the base: english_word_to_finnish_phoneme.ipynb.\n",
    "\n",
    "Author: Sujith Padaru\n",
    "- *Inputs*: \n",
    "    - Game words\n",
    "    - English Dict, word, phoneme representation form. *[hard coded for en_uk].\n",
    "    - Finnish dict,\n",
    "    - Eng to Global map. Pickle of a dictionary with {phoneme -> phoneme rep}\n",
    "    - Finnish to Global Map.\n",
    "    - Global phone distances.\n",
    "    \n",
    "\n",
    "- *Outputs*: \n",
    "    - n finnish phonetical representation for each word.\n",
    "- *HyperParameters*:\n",
    "    - n number of samples to generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from itertools import product\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " Code to Run the below file as a script to generate english words to generate based on different distance \n",
    " metrics and english and finnihs dictionaries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_eng_sentence_2_en_uk_phone_rep(sentence):\n",
    "    '''\n",
    "    inputs:\n",
    "    sentence: (str) Sentence which needs to be represented in phones.\n",
    "    outputs:\n",
    "    transcripts (str)['ph ph ph'] Phoneme representation of sentence.\n",
    "    '''\n",
    "    \n",
    "    # Save transcript for each word in the sentence in a list transcripts.\n",
    "    global en_uk_dict\n",
    "    words = sentence.split(' ')    \n",
    "    print(words)\n",
    "    word_transcripts = []\n",
    "    for word in words:\n",
    "        if word not in en_uk_dict.keys():\n",
    "            print('Some words not found')\n",
    "            # return ''\n",
    "        else:\n",
    "            word_transcripts.append(en_uk_dict[word])\n",
    "    \n",
    "    #Take the transcripts in the transcript list and make a phoneme representation.\n",
    "    # Taking care if it's a single word or a sentence.\n",
    "    print(word_transcripts)\n",
    "    sentence_transcript = ''\n",
    "    if len(word_transcripts) == 1:\n",
    "        sentence_transcript += word_transcripts[0]\n",
    "    else:\n",
    "        for i in word_transcripts:\n",
    "            sentence_transcript += i \n",
    "            sentence_transcript += \" sil \"\n",
    "\n",
    "    return sentence_transcript.rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eng_ph_2_global_ph(english_ph_transcript):\n",
    "    '''\n",
    "    input: \n",
    "    english_ph_transcript - English phone transcripts from mapping file. 'ph ph ph ...'\n",
    "    output: \n",
    "    global_ph_transcript: 'ph ph ph ...'\n",
    "    Hyperparameter: eng_to_global_map.\n",
    "    '''\n",
    "    global_ph_transcript = ''\n",
    "    for phone in english_ph_transcript.split(\" \"):\n",
    "        global_ph_transcript += eng_to_global_map[phone]\n",
    "        global_ph_transcript += ' '\n",
    "    \n",
    "    return global_ph_transcript.rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glob_transcript_2_fin_nearest(transcript):\n",
    "    '''Returns the nearest finnish phoneme to each of the global transcript\n",
    "       Input: Global phoneme representation seperated by a space\n",
    "       Output: Finnish phoneme representation seperated by space.\n",
    "    '''\n",
    "    fin_transcript = ''\n",
    "    for phone in transcript.split(\" \"):\n",
    "         \n",
    "        if type(global_2_fin_map[phone]) is list:\n",
    "            fin_transcript += global_2_fin_map[phone][0]\n",
    "        else:\n",
    "            fin_transcript += global_2_fin_map[phone]       \n",
    "        \n",
    "        fin_transcript += ' '\n",
    "    return fin_transcript.rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glob_transcript_2_N_fin(transcript):\n",
    "    '''Returns the nearest finnish phoneme to each of the global transcript\n",
    "       Input: Global phoneme representation seperated by a space\n",
    "       Output: Finnish phoneme representation seperated by space.\n",
    "    '''\n",
    "    \n",
    "    phone_maps = []\n",
    "    for phone in transcript.split(\" \"):\n",
    "        if phone == 'sil':\n",
    "            phone_maps.append(['sil'])\n",
    "        else:\n",
    "            phone_maps.append(global_2_fin_map[phone])\n",
    "    \n",
    "    list_of_trans = list(product(*phone_maps))    \n",
    "    list_of_trans = [\" \".join(list(trans)) for trans in list_of_trans]\n",
    "    return list_of_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f y sil sil d y sil f i s t sil tʰ æe m sil e n sil m i m y rː iː sil p rː y d j uː s y sil sil y n d sil k y n s j uː m y sil sil p rː æe s sil rː e p o t s sil h e t sil b æ k sil tʰ y sil b æ k sil e n sil d y sil s e m sil m iː k sil'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping.fin_transcript[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phone_sentences(sentence):\n",
    "    sentence = sentence.replace(\"  \",\"sil\")\n",
    "    sentence = sentence.replace(\" \",\"\")\n",
    "    sentence = sentence.replace(\"sil\",\" \")\n",
    "    return sentence\n",
    "\n",
    "def mappings_2_text(index='all',speakers=[600], name='eng_game_words'):\n",
    "    '''\n",
    "    Input : \n",
    "    Index - Index of the the mapping file to be written into a evaluation file.\n",
    "                Default : all the words\n",
    "    speakers - List of speakers the be generated by tacotron.\n",
    "    name - Name of the output text file\n",
    "    \n",
    "    Output:\n",
    "    None, Saves the file in the eval_text/folder. \n",
    "    '''\n",
    "    if index == 'all':\n",
    "        transcript_2_text = mapping[['sentence','fin_transcript']]\n",
    "    else:\n",
    "        transcript_2_text = mapping.iloc[index][['sentence','fin_transcript']]\n",
    "\n",
    "    #transcript_2_text.set_index('sentence',inplace=True)\n",
    "    transcript_2_text = transcript_2_text.assign(\n",
    "                                fin_transcript=transcript_2_text.fin_transcript.apply(phone_sentences))\n",
    "    for speaker in speakers:\n",
    "        transcript_2_text = transcript_2_text.assign(speaker_id = len(transcript_2_text)*[speaker])\n",
    "        \n",
    "        my_file = Path('eval_text/{}_{}.txt'.format(name,speaker))\n",
    "        \n",
    "        if my_file.is_file():\n",
    "            print('eval_text/{}_{}.txt already exists; not writing the file'.format(name,speaker))\n",
    "        else:    \n",
    "            transcript_2_text.to_csv('eval_text/{}_{}.txt'.format(name,speaker), sep='|', header=False)\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mappings_2_text_N(N=20, index='all', speakers=[600], name='eng_game_words'):\n",
    "    '''\n",
    "    Input : \n",
    "    N : Number of alternate Finnish phonemic representation for each game word.\n",
    "    Index - Index of the the mapping file to be written into a evaluation file.\n",
    "                Default : all the words\n",
    "    speakers - List of speakers the be generated by tacotron.\n",
    "    name - Name of the output text file\n",
    "    \n",
    "    Output:\n",
    "    None, Saves the file in the eval_text/folder. \n",
    "    '''\n",
    "    if index == 'all':\n",
    "        transcript_2_text = mapping[['sentence','all_fin_transcripts']]\n",
    "    else:\n",
    "        transcript_2_text = mapping.iloc[index][['sentence','all_fin_transcripts']]\n",
    "\n",
    "    transcript_2_text.set_index('sentence',inplace=True)\n",
    "    \n",
    "    dfs = []\n",
    "    for sentence, all_fin_transcripts in transcript_2_text.iterrows():\n",
    "        list_of_trans = all_fin_transcripts.values[0]\n",
    "        number_of_trans = len(list_of_trans)\n",
    "\n",
    "        if number_of_trans > 20:\n",
    "            np.random.seed(0)\n",
    "            transcripts = np.random.choice(list_of_trans, size=20, replace=False)\n",
    "            df = pd.DataFrame(transcripts)\n",
    "            df = df.assign(sentence = 20*[sentence])\n",
    "        else:\n",
    "            df = pd.DataFrame(list_of_trans)\n",
    "            df = df.assign(sentence = number_of_trans*[sentence])\n",
    "        dfs.append(df)\n",
    "    \n",
    "    transcript_2_text = pd.concat(dfs)\n",
    "    transcript_2_text.set_index('sentence',inplace=True)\n",
    "    \n",
    "    for speaker in speakers:\n",
    "        transcript_2_text = transcript_2_text.assign(speaker_id = len(transcript_2_text)*[speaker])\n",
    "        \n",
    "        my_file = Path('eval_text/{}_{}.txt'.format(name,speaker))\n",
    "        \n",
    "        if my_file.is_file():\n",
    "            print('eval_text/{}_{}.txt already exists; not writing the file'.format(name,speaker))\n",
    "        else:    \n",
    "            transcript_2_text.to_csv('eval_text/{}_spk_{}.txt'.format(name,speaker), sep='|', header=False)\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## __main__():\n",
    "Read the Game Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport argparse\\n\\nparser = argparse.ArgumentParser(description=\\'Outputs the Finnish Phoneme representation of the english words\\')\\n\\nparser.add_argument(\"word_list\",help=\"Path to the text file to be converted to Finnish phonetic symbols\",type=str)\\nparser.add_argument(\"-ed\",\"--english_dict\",default=\"dict/en_uk_dict.txt\")\\nparser.add_argument(\\'--eng_to_global_map\\', default=\\'../mappings/en_uk_ph_dist_phones_map.pkl\\',\\n                    help=\"Path to the english to global phoneme dictionary mapping\", type=str)\\nparser.add_argument(\\'--fin_to_global_map\\', default=\\'../mappings/fin_2_global_phones_map.pkl\\',\\n                    help=\"Path to the finnish to global phoneme dictionary mapping\", type=str)\\nparser.add_argument(\\'--global_phone_distances\\', default=\\'../mappings/global_phone_distances.pkl\\',\\n                    help=\"Path to the english to global phoneme dictionary mapping\", type=str)\\nargs = parser.parse_args()\\n\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Outputs the Finnish Phoneme representation of the english words')\n",
    "\n",
    "parser.add_argument(\"word_list\",help=\"Path to the text file to be converted to Finnish phonetic symbols\",type=str)\n",
    "parser.add_argument(\"-ed\",\"--english_dict\",default=\"dict/en_uk_dict.txt\")\n",
    "parser.add_argument('--eng_to_global_map', default='../mappings/en_uk_ph_dist_phones_map.pkl',\n",
    "                    help=\"Path to the english to global phoneme dictionary mapping\", type=str)\n",
    "parser.add_argument('--fin_to_global_map', default='../mappings/fin_2_global_phones_map.pkl',\n",
    "                    help=\"Path to the finnish to global phoneme dictionary mapping\", type=str)\n",
    "parser.add_argument('--global_phone_distances', default='../mappings/global_phone_distances.pkl',\n",
    "                    help=\"Path to the english to global phoneme dictionary mapping\", type=str)\n",
    "args = parser.parse_args()\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Adding the words/sentences to be translated to a **mapping** file, where the further mappings can be representated.\n",
    "mapping = pd.read_csv('eval_text/w1_s1newart_clean_no_unk.trn',header=None,names=['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>for the first time in memory producer and cons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unlisted share prices slipped in muted trading...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a stronger dollar helped clobber tokyo stocks ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tomorrow the house will vote for only the seco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>brother pierre is extolling the virtues of his...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence\n",
       "0  for the first time in memory producer and cons...\n",
       "1  unlisted share prices slipped in muted trading...\n",
       "2  a stronger dollar helped clobber tokyo stocks ...\n",
       "3  tomorrow the house will vote for only the seco...\n",
       "4  brother pierre is extolling the virtues of his..."
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Read the English Dictionary \n",
    "- preprocess it\n",
    "- Convert english word rep to eng phoneme rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['for', 'the', 'first', 'time', 'in', 'memory', 'producer', 'and', 'consumer', 'price', 'reports', 'hit', 'back', 'to', 'back', 'in', 'the', 'same', 'week', '']\n",
      "Some words not found\n",
      "['f ə ', 'ð ə', 'f ɜː s t', 'tʰ aɪ m', 'ɪ n', 'm ɛ m ə ɹ iː', 'p ɹ ə d j uː s ə ', 'ə n d', 'kʰ ə n s j uː m ə ', 'p ɹ aɪ s', 'ɹ ɪ pʰ ɔː t s', 'h ɪ t', 'b a k', 'tʰ ə', 'b a k', 'ɪ n', 'ð ə', 's eɪ m', 'w iː k']\n",
      "['unlisted', 'share', 'prices', 'slipped', 'in', 'muted', 'trading', 'yesterday', 'depressed', 'by', 'weaker', 'equity', 'markets', 'overseas', '']\n",
      "Some words not found\n",
      "['ʌ n l ɪ s t ɪ d', 'ʃ ɛə ', 'p ɹ aɪ s ɪ z', 's l ɪ p t', 'ɪ n', 'm j uː t ɪ d', 't ɹ eɪ d ɪ ŋ', 'j ɛ s t ə d iː', 'd ɪ p ɹ ɛ s t', 'b aɪ', 'w iː k ə ', 'ɛ k w ə t iː', 'm ɑː k ɪ t s', 'əʊ v ə s iː z']\n",
      "['a', 'stronger', 'dollar', 'helped', 'clobber', 'tokyo', 'stocks', 'which', 'in', 'turn', 'pulled', 'u.', 's.', 'stock', 'prices', 'modestly', 'lower', '']\n",
      "Some words not found\n",
      "Some words not found\n",
      "Some words not found\n",
      "['ə', 's t ɹ ɒ ŋ g ə ', 'd ɒ l ə ', 'h ɛ ɫ p t', 'k l ɒ b ə ', 'tʰ əʊ k iː əʊ', 's t ɒ k s', 'w ɪ tʃ', 'ɪ n', 'tʰ ɜː n', 'p ʊ ɫ d', 's t ɒ k', 'p ɹ aɪ s ɪ z', 'm ɒ d ɪ s t l iː', 'l əʊ ə ']\n",
      "['tomorrow', 'the', 'house', 'will', 'vote', 'for', 'only', 'the', 'second', 'time', 'in', 'history', 'on', 'a', 'balanced', 'budget', 'amendment', 'to', 'the', 'constitution', '']\n",
      "Some words not found\n",
      "['tʰ ə m ɒ ɹ əʊ', 'ð ə', 'h aʊ z', 'w ɪ ɫ', 'v əʊ t', 'f ə ', 'əʊ n l iː', 'ð ə', 's ɪ kʰ ɒ n d', 'tʰ aɪ m', 'ɪ n', 'h ɪ s t ɹ iː', 'ɒ n', 'ə', 'b a l ə n s t', 'b ʌ dʒ ɪ t', 'ə m ɛ n d m ə n t', 'tʰ ə', 'ð ə', 'kʰ ɒ n s t ɪ t j uː ʃ n̩']\n",
      "['brother', 'pierre', 'is', 'extolling', 'the', 'virtues', 'of', 'his', 'monastic', 'life', 'fulfilling', 'work', 'in', 'the', \"abbey's\", 'small', 'brewery', 'along', 'with', 'plenty', 'of', 'time', 'for', 'study', 'reflection', 'and', 'prayer', '']\n",
      "Some words not found\n",
      "['b ɹ ʌ ð ə ', 'pʰ ɪə ', 'ɪ z', 'ɪ k s t əʊ l ɪ ŋ', 'ð ə', 'v ɜː tʃ uː z', 'ə v', 'ɪ z', 'm ə n a s t ɪ k', 'l aɪ f', 'f ʊ ɫ f ɪ l ɪ ŋ', 'w ɜː k', 'ɪ n', 'ð ə', 'a b iː z', 's m ɔː ɫ', 'b ɹ uː ə ɹ iː', 'ə l ɒ ŋ', 'w ɪ ð', 'p l ɛ n t iː', 'ə v', 'tʰ aɪ m', 'f ə ', 's t ʌ d iː', 'ɹ ɪ f l ɛ k ʃ n̩', 'ə n d', 'p ɹ ɛə ']\n",
      "['a', 'majority', 'of', 'americans', 'the', 'polls', 'say', 'favor', 'military', 'action', 'against', 'iraq', 'even', 'if', 'their', 'fellow', 'americans', 'are', 'still', 'trapped', 'there', '']\n",
      "Some words not found\n",
      "['ə', 'm ə dʒ ɒ ɹ ə t iː', 'ə v', 'ə m ɛ ɹ ɪ k ə n z', 'ð ə', 'pʰ əʊ ɫ z', 's eɪ', 'f eɪ v ə ', 'm ɪ l ɪ t ɹ iː', 'a k ʃ n̩', 'ə g ɛ n s t', 'ɪ ɹ ɑː k', 'iː v n̩', 'ɪ f', 'ð ɛə ', 'f ɛ l əʊ', 'ə m ɛ ɹ ɪ k ə n z', 'ə ', 's t ɪ ɫ', 't ɹ a p t', 'ð ɛə ɹ s']\n",
      "['your', 'november', 'nineteenth', 'page', 'one', 'article', 'about', 'drugs', 'and', 'public', 'opinion', 'revealed', 'the', 'persistence', 'of', 'the', 'drug', 'crisis', 'but', 'understated', \"americans'\", 'resolve', 'to', 'confront', 'the', 'problem', '']\n",
      "Some words not found\n",
      "['j ʊə ', 'n əʊ v ɛ m b ə ', 'n aɪ n tʰ iː n θ', 'pʰ eɪ dʒ', 'w ʌ n', 'ɑː t ɪ k ə ɫ', 'ə b aʊ t', 'd ɹ ʌ g z', 'ə n d', 'p ʌ b l ɪ k', 'ə pʰ ɪ n j ə n', 'ɹ ɪ v iː ɫ d', 'ð ə', 'pʰ ə s ɪ s t n̩ s', 'ə v', 'ð ə', 'd ɹ ʌ g', 'k ɹ aɪ s ɪ s', 'b ʌ t', 'ʌ n d ə s t eɪ t ɪ d', 'ə m ɛ ɹ ɪ k ə n z', 'ɹ ɪ z ɒ ɫ v', 'tʰ ə', 'kʰ ə n f ɹ ʌ n t', 'ð ə', 'p ɹ ɒ b l ə m']\n",
      "['stephen', 'sander', 'ushers', 'a', 'visitor', 'into', 'the', 'meditation', 'room', 'of', 'his', 'home', '']\n",
      "Some words not found\n",
      "['s t iː v n̩', 's a n d ə ', 'ʌ ʃ ə z', 'ə', 'v ɪ z ɪ t ə ', 'ɪ n t ə', 'ð ə', 'm ɛ d ɪ tʰ eɪ ʃ n̩', 'ɹ ʊ m', 'ə v', 'ɪ z', 'h əʊ m']\n",
      "['g.', 'm.', 'is', 'to', 'announce', 'today', 'that', 'its', 'president', 'robert', 'c.', 'stempel', 'will', 'be', 'named', 'chairman', 'and', 'chief', 'executive', 'succeeding', 'roger', 'b.', 'smith', 'who', 'is', 'to', 'retire', 'august', 'first', '']\n",
      "Some words not found\n",
      "Some words not found\n",
      "Some words not found\n",
      "Some words not found\n",
      "Some words not found\n",
      "Some words not found\n",
      "['ɪ z', 'tʰ ə', 'ə n aʊ n s', 'tʰ ə d eɪ', 'ð ə t', 'ɪ t s', 'p ɹ ɛ z ɪ d n̩ t', 'ɹ ɒ b ə t', 'w ɪ ɫ', 'b iː', 'n eɪ m d', 'tʃ ɛə m ə n', 'ə n d', 'tʃ iː f', 'ɪ g z ɛ k j ə t ɪ v', 's ə k s iː d ɪ ŋ', 'ɹ ɒ dʒ ə ', 's m ɪ θ', 'h uː', 'ɪ z', 'tʰ ə', 'ɹ ɪ tʰ aɪ ə ', 'ɔː g ʌ s t', 'f ɜː s t']\n",
      "['', 'a', 'funding', 'pinch', 'hampers', \"states'\", 'jobless', 'pay', 'operations', '']\n",
      "Some words not found\n",
      "Some words not found\n",
      "['ə', 'f ʌ n d ɪ ŋ', 'pʰ ɪ n tʃ', 'h a m p ə z', 's t eɪ t s', 'dʒ ɒ b l ə s', 'pʰ eɪ', 'ɒ p ə ɹ eɪ ʃ n̩ z']\n",
      "['', 'the', 'drought', 'stricken', 'city', 'of', 'santa', 'barbara', 'california', 'is', 'turning', 'to', 'the', 'pacific', 'ocean', 'to', 'help', 'satisfy', 'the', 'thirst', 'of', 'its', 'parched', 'residents', '']\n",
      "Some words not found\n",
      "Some words not found\n",
      "['ð ə', 'd ɹ aʊ t', 's t ɹ ɪ k ə n', 's ɪ t iː', 'ə v', 's a n t ə', 'b ɑː b ɹ ə', 'kʰ a l ɪ f ɔː n j ə', 'ɪ z', 'tʰ ɜː n ɪ ŋ', 'tʰ ə', 'ð ə', 'pʰ ə s ɪ f ɪ k', 'əʊ ʃ n̩', 'tʰ ə', 'h ɛ ɫ p', 's a t ɪ s f aɪ', 'ð ə', 'θ ɜː s t', 'ə v', 'ɪ t s', 'pʰ ɑː tʃ t', 'ɹ ɛ z ɪ d n̩ t s']\n",
      "['swiss', 'voters', 'go', 'to', 'the', 'polls', 'sunday', 'to', 'decide', 'on', 'a', 'future', 'with', 'or', 'without', 'nuclear', 'power', '']\n",
      "Some words not found\n",
      "['s w ɪ s', 'v əʊ t ə z', 'g əʊ', 'tʰ ə', 'ð ə', 'pʰ əʊ ɫ z', 's ʌ n d iː', 'tʰ ə', 'd ɪ s aɪ d', 'ɒ n', 'ə', 'f j uː tʃ ə ', 'w ɪ ð', 'ə ', 'w ɪ ð aʊ t', 'n j uː k l iː ə ', 'pʰ aʊ ə ']\n",
      "['the', 'fed', 'authorized', 'j.', 'p.', 'morgan', 'to', 'underwrite', 'stocks', 'the', 'first', 'time', 'a', 'bank', 'has', 'had', 'that', 'power', 'since', 'it', 'was', 'outlawed', 'in', 'nineteen', 'thirty', 'three', 'because', 'of', 'abuses', 'during', 'the', 'depression', '']\n",
      "Some words not found\n",
      "Some words not found\n",
      "Some words not found\n",
      "['ð ə', 'f ɛ d', 'ɔː θ ə ɹ aɪ z d', 'm ɔː g ə n', 'tʰ ə', 'ʌ n d ə ɹ aɪ t', 's t ɒ k s', 'ð ə', 'f ɜː s t', 'tʰ aɪ m', 'ə', 'b a ŋ k', 'h ə z', 'ə d', 'ð ə t', 'pʰ aʊ ə ', 's ɪ n s', 'ɪ t', 'w ə z', 'aʊ t l ɔː d', 'ɪ n', 'n aɪ n tʰ iː n', 'θ ɜː t iː', 'θ ɹ iː', 'b ɪ kʰ ɒ z', 'ə v', 'ə b j uː z ɪ z', 'd j ʊə ɹ ɪ ŋ', 'ð ə', 'd ɪ p ɹ ɛ ʃ n̩']\n",
      "['', 'the', 'bond', 'market', 'was', 'knocked', 'down', 'with', 'a', 'one', 'two', 'punch', 'yesterday', 'staggering', 'first', 'on', 'news', 'of', 'rising', 'inflation', 'then', 'tumbling', 'after', 'a', 'menacing', 'speech', 'by', 'iraqi', 'president', 'saddam', 'hussein', '']\n",
      "Some words not found\n",
      "Some words not found\n",
      "['ð ə', 'b ɒ n d', 'm ɑː k ɪ t', 'w ə z', 'n ɒ k t', 'd aʊ n', 'w ɪ ð', 'ə', 'w ʌ n', 'tʰ uː', 'p ʌ n tʃ', 'j ɛ s t ə d iː', 's t a g ə ɹ ɪ ŋ', 'f ɜː s t', 'ɒ n', 'n j uː z', 'ə v', 'ɹ aɪ z ɪ ŋ', 'ɪ n f l eɪ ʃ n̩', 'ð ɛ n', 't ʌ m b ə l ɪ ŋ', 'ɑː f t ə ', 'ə', 'm ɛ n ɪ s ɪ ŋ', 's p iː tʃ', 'b aɪ', 'ɪ ɹ ɑː k iː', 'p ɹ ɛ z ɪ d n̩ t', 's ə d ɑː m', 'h ə s eɪ n']\n",
      "['we', 'are', 'tempted', 'beyond', 'endurance', 'so', 'we', 'hereby', 'enthusiastically', 'cheer', 'passage', 'of', \"pennsylvania's\", 'proposed', 'anti', 'takeover', 'anti', 'proxy', 'bill', '']\n",
      "Some words not found\n",
      "['w ɪ', 'ə ', 'tʰ ɛ m p t ɪ d', 'b ɪ j ɒ n d', 'ɪ n d j ʊə ɹ ə n s', 's əʊ', 'w ɪ', 'h ɪə b aɪ', 'ɪ n θ j uː z iː a s t ɪ k l iː', 'tʃ ɪə ', 'pʰ a s ɪ dʒ', 'ə v', 'pʰ ɛ n s ɪ ɫ v eɪ n j ə z', 'p ɹ ə pʰ əʊ z d', 'a n t iː', 'tʰ eɪ k əʊ v ə ', 'a n t iː', 'p ɹ ɒ k s iː', 'b ɪ ɫ']\n",
      "[\"don't\", 'be', 'surprised', 'however', 'if', 'the', 'hundredth', 'congress', 'soon', 'finds', 'itself', 'reforming', 'the', 'mess', 'the', 'immigration', 'reform', 'bill', 'creates', '']\n",
      "Some words not found\n",
      "['d əʊ n t', 'b iː', 's ə p ɹ aɪ z d', 'h aʊ ɛ v ə ', 'ɪ f', 'ð ə', 'h ʌ n d ɹ ə d θ', 'kʰ ə ŋ g ɹ ɛ s', 's uː n', 'f aɪ n d z', 'ɪ t s ɛ ɫ f', 'ɹ ɪ f ɔː m ɪ ŋ', 'ð ə', 'm ɛ s', 'ð ə', 'ɪ m ɪ g ɹ eɪ ʃ n̩', 'ɹ ɪ f ɔː m', 'b ɪ ɫ', 'k ɹ iː eɪ t s']\n",
      "[\"canada's\", 'leaders', 'patched', 'together', 'a', 'tentative', 'agreement', 'that', 'would', 'give', 'quebec', 'special', 'status', 'and', 'end', 'a', 'bitter', 'constitutional', 'impasse', 'that', 'has', 'revived', 'talk', 'of', 'independence', 'in', 'the', 'french', 'speaking', 'province', '']\n",
      "Some words not found\n",
      "['kʰ a n ə d ə z', 'l iː d ə z', 'pʰ a tʃ t', 'tʰ ə g ɛ ð ə ', 'ə', 'tʰ ɛ n t ə t ɪ v', 'ə g ɹ iː m ə n t', 'ð ə t', 'w ʊ d', 'g ɪ v', 'k w ɪ b ɛ k', 's p ɛ ʃ l̩', 's t eɪ t ə s', 'ə n d', 'ɛ n d', 'ə', 'b ɪ t ə ', 'kʰ ɒ n s t ɪ t j uː ʃ n̩ l̩', 'a m p a s', 'ð ə t', 'h ə z', 'ɹ ɪ v aɪ v d', 'tʰ ɔː k', 'ə v', 'ɪ n d ɪ pʰ ɛ n d n̩ s', 'ɪ n', 'ð ə', 'f ɹ ɛ n tʃ', 's p iː k ɪ ŋ', 'p ɹ ɒ v ɪ n s']\n",
      "['state', 'regulators', 'here', 'knew', 'life', 'assurance', 'company', 'of', 'pennsylvania', 'was', 'in', 'trouble', '']\n",
      "Some words not found\n",
      "['s t eɪ t', 'ɹ ɛ g j ə l eɪ t ə z', 'h ɪə ', 'n j uː', 'l aɪ f', 'ə ʃ ʊə ɹ ə n s', 'k ʌ m p ə n iː', 'ə v', 'pʰ ɛ n s ɪ ɫ v eɪ n j ə', 'w ə z', 'ɪ n', 't ɹ ʌ b ə ɫ']\n",
      "['at', 'nintendo', 'customer', 'feedback', 'helps', 'us', 'deliver', 'top', 'quality', 'entertainment', 'products', '']\n",
      "Some words not found\n",
      "['ə t', 'n ɪ n tʰ ɛ n d əʊ', 'k ʌ s t ə m ə ', 'f iː d b a k', 'h ɛ ɫ p s', 'ʌ s', 'd ɪ l ɪ v ə ', 'tʰ ɒ p', 'k w ɒ l ə t iː', 'ɛ n t ə tʰ eɪ n m ə n t', 'p ɹ ɒ d ʌ k t s']\n",
      "'The Dataframe after mapping english words to phonemes:'\n",
      "                                            sentence  \\\n",
      "0  for the first time in memory producer and cons...   \n",
      "1  unlisted share prices slipped in muted trading...   \n",
      "2  a stronger dollar helped clobber tokyo stocks ...   \n",
      "3  tomorrow the house will vote for only the seco...   \n",
      "4  brother pierre is extolling the virtues of his...   \n",
      "\n",
      "                                      eng_transcript  no_transcript_flag  \n",
      "0  f ə  sil ð ə sil f ɜː s t sil tʰ aɪ m sil ɪ n ...               False  \n",
      "1  ʌ n l ɪ s t ɪ d sil ʃ ɛə  sil p ɹ aɪ s ɪ z sil...               False  \n",
      "2  ə sil s t ɹ ɒ ŋ g ə  sil d ɒ l ə  sil h ɛ ɫ p ...               False  \n",
      "3  tʰ ə m ɒ ɹ əʊ sil ð ə sil h aʊ z sil w ɪ ɫ sil...               False  \n",
      "4  b ɹ ʌ ð ə  sil pʰ ɪə  sil ɪ z sil ɪ k s t əʊ l...               False  \n"
     ]
    }
   ],
   "source": [
    "# Reading and preprocessing the english dictionary. \n",
    "# English Dictionary should be a text file with each line representeda s follows\n",
    "# language_dialect_word [\\t tab] phone[space]phone[space]...\n",
    "\n",
    "en_uk_dict = pd.read_csv('dict/en_uk_dict.txt',header=None,names=['word','en_rep'],sep='\\t')#,index_col=['word'])\n",
    "\n",
    "#Removing 'language_dialect_' part\n",
    "word_after_remov_en_uk = en_uk_dict.word.apply(lambda en_uk_word: en_uk_word.split('_')[-1])\n",
    "en_uk_dict.set_index(word_after_remov_en_uk,inplace=True)\n",
    "en_uk_dict.drop('word',axis=1,inplace=True)\n",
    "#pprint('English Phoneme Representation samples:')\n",
    "#pprint(en_uk_dict.head())\n",
    "\n",
    "en_uk_dict = en_uk_dict.to_dict()['en_rep']\n",
    "#Add the English phoneme representation to the mapping dataframe            \n",
    "mapping =mapping.assign(eng_transcript= mapping.sentence.apply(map_eng_sentence_2_en_uk_phone_rep))\n",
    "mapping = mapping.assign(no_transcript_flag=(mapping.eng_transcript==''))\n",
    "pprint('The Dataframe after mapping english words to phonemes:')\n",
    "pprint(mapping.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Read English phoneme to Global Phoneme Map\n",
    "- Eng phoneme rep to Global Phoneme rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the English to Global rep and make the mapping in the file.\n",
    "\n",
    "\n",
    "'''Reading the pprint english to global map dictionary\n",
    "{'': '',\n",
    " 'ɒ': 'ɒ',\n",
    " .\n",
    " .\n",
    " .\n",
    " }\n",
    "'''\n",
    "\n",
    "eng_to_global_map = pd.read_pickle('mappings/en_uk_ph_dist_phones_map.pkl')\n",
    "#eng_to_global_map = pd.read_pickle(args.eng_to_global_map)\n",
    "\n",
    "\n",
    "mapping = mapping.assign(global_transcript = mapping.eng_transcript.apply(eng_ph_2_global_ph))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Read Finnish phoneme map to Global Map\n",
    "- Read Global Phone Distance\n",
    "- Infer Global phone to Finnish Phone Map\n",
    "- Find Finnish Phoneme Rep from Global Rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            sentence  \\\n",
      "0  for the first time in memory producer and cons...   \n",
      "1  unlisted share prices slipped in muted trading...   \n",
      "2  a stronger dollar helped clobber tokyo stocks ...   \n",
      "3  tomorrow the house will vote for only the seco...   \n",
      "4  brother pierre is extolling the virtues of his...   \n",
      "\n",
      "                                      eng_transcript  no_transcript_flag  \\\n",
      "0  f ə  sil ð ə sil f ɜː s t sil tʰ aɪ m sil ɪ n ...               False   \n",
      "1  ʌ n l ɪ s t ɪ d sil ʃ ɛə  sil p ɹ aɪ s ɪ z sil...               False   \n",
      "2  ə sil s t ɹ ɒ ŋ g ə  sil d ɒ l ə  sil h ɛ ɫ p ...               False   \n",
      "3  tʰ ə m ɒ ɹ əʊ sil ð ə sil h aʊ z sil w ɪ ɫ sil...               False   \n",
      "4  b ɹ ʌ ð ə  sil pʰ ɪə  sil ɪ z sil ɪ k s t əʊ l...               False   \n",
      "\n",
      "                                   global_transcript  \\\n",
      "0  f ə sil sil ð ə sil f ɜ s t sil tʰ aɪ m sil ɪ ...   \n",
      "1  ʌ n l ɪ s t ɪ d sil ʃ ɛə sil sil p ɹ aɪ s ɪ z ...   \n",
      "2  ə sil s t ɹ ɒ ŋ g ə sil sil d ɒ l ə sil sil h ...   \n",
      "3  tʰ ə m ɒ ɹ əʊ sil ð ə sil h aʊ z sil w ɪ ɫ sil...   \n",
      "4  b ɹ ʌ ð ə sil sil pʰ ɪə sil sil ɪ z sil ɪ k s ...   \n",
      "\n",
      "                                      fin_transcript  \n",
      "0  f y sil sil d y sil f i s t sil tʰ æe m sil e ...  \n",
      "1  ɑ n l e s t e d sil s i sil sil p rː æe s e d ...  \n",
      "2  y sil s t rː ɑ ŋ g y sil sil d ɑ l y sil sil h...  \n",
      "3  tʰ y m ɑ rː y sil d y sil h ɑu d sil m e l sil...  \n",
      "4  b rː ɑ d y sil sil p ie sil sil e d sil e k s ...  \n"
     ]
    }
   ],
   "source": [
    "# Read the Fin to Global Map and compute Global to Finnish Map.\n",
    "\n",
    "fin_to_global_map = pd.read_pickle('mappings/fin_2_global_phones_map.pkl')\n",
    "global_2_fin_map = dict([[value,key] for key,value in fin_to_global_map.items()])\n",
    "\n",
    "global_phone_dist = pd.read_pickle('mappings/phone_distances.pickle')\n",
    "\n",
    "global_ph = global_phone_dist['phones']\n",
    "global_ph_dist = global_phone_dist['phone_distances']\n",
    "\n",
    "global_ph_dist = pd.DataFrame(data=global_ph_dist,index=global_ph.values(),columns=global_ph.values())\n",
    "\n",
    "distance_2_fin = global_ph_dist.loc[global_2_fin_map.keys()]\n",
    "\n",
    "for ph in global_ph.values():\n",
    "    three_nearest_phones = list(distance_2_fin[ph].sort_values()[:3].index)\n",
    "    global_2_fin_map[ph] = three_nearest_phones\n",
    "\n",
    "\n",
    "global_2_fin_map['w'] = np.concatenate([global_2_fin_map['w'][:2],['v']])\n",
    "global_2_fin_map['w'] = list(global_2_fin_map['w'])\n",
    "global_2_fin_map['z'] = np.concatenate([global_2_fin_map['z'][:2],['s']])\n",
    "global_2_fin_map['z'] = list(global_2_fin_map['z'])\n",
    "\n",
    "mapping = mapping.assign(fin_transcript=mapping.global_transcript.apply(glob_transcript_2_fin_nearest))\n",
    "pprint(mapping.head(5))\n",
    "\n",
    "\n",
    "#mapping = mapping.assign(all_fin_transcripts =\n",
    "#                         mapping.global_transcript.apply(glob_transcript_2_N_fin))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create the Dataframe to save the evaluation file.\n",
    "- Save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating 20 fin reps for 5 random words with speaker, 600, 555, 567 and 57, 258 \n",
    "\n",
    "rand_spks = [600, 555, 567, 57, 258]\n",
    "mappings_2_text(speakers=rand_spks, name='wsj_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>eng_transcript</th>\n",
       "      <th>no_transcript_flag</th>\n",
       "      <th>global_transcript</th>\n",
       "      <th>fin_transcript</th>\n",
       "      <th>all_fin_transcripts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>girl</td>\n",
       "      <td>g ɜː ɫ</td>\n",
       "      <td>False</td>\n",
       "      <td>g ɜ ɫ</td>\n",
       "      <td>g i l</td>\n",
       "      <td>[g i l, g i lː, g i rː, g æ l, g æ lː, g æ rː,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hello</td>\n",
       "      <td>h ɛ l əʊ</td>\n",
       "      <td>False</td>\n",
       "      <td>h ɛ l əʊ</td>\n",
       "      <td>h i l ou</td>\n",
       "      <td>[h i l ou, h i l u, h i l y, h i lː ou, h i lː...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>book</td>\n",
       "      <td>b ʊ k</td>\n",
       "      <td>False</td>\n",
       "      <td>b ʊ k</td>\n",
       "      <td>b u k</td>\n",
       "      <td>[b u k, b u kː, b u p, b y k, b y kː, b y p, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>learn</td>\n",
       "      <td>l ɜː n</td>\n",
       "      <td>False</td>\n",
       "      <td>l ɜ n</td>\n",
       "      <td>l i n</td>\n",
       "      <td>[l i n, l i nː, l i rː, l æ n, l æ nː, l æ rː,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bye bye</td>\n",
       "      <td>b aɪ sil b aɪ sil</td>\n",
       "      <td>False</td>\n",
       "      <td>b aɪ sil b aɪ sil</td>\n",
       "      <td>b æe sil b æe sil</td>\n",
       "      <td>[b æe sil b æe sil, b æe sil b ɑe sil, b æe si...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentence     eng_transcript  no_transcript_flag  global_transcript  \\\n",
       "0     girl             g ɜː ɫ               False              g ɜ ɫ   \n",
       "1    hello           h ɛ l əʊ               False           h ɛ l əʊ   \n",
       "2     book              b ʊ k               False              b ʊ k   \n",
       "3    learn             l ɜː n               False              l ɜ n   \n",
       "4  bye bye  b aɪ sil b aɪ sil               False  b aɪ sil b aɪ sil   \n",
       "\n",
       "      fin_transcript                                all_fin_transcripts  \n",
       "0              g i l  [g i l, g i lː, g i rː, g æ l, g æ lː, g æ rː,...  \n",
       "1           h i l ou  [h i l ou, h i l u, h i l y, h i lː ou, h i lː...  \n",
       "2              b u k  [b u k, b u kː, b u p, b y k, b y kː, b y p, b...  \n",
       "3              l i n  [l i n, l i nː, l i rː, l æ n, l æ nː, l æ rː,...  \n",
       "4  b æe sil b æe sil  [b æe sil b æe sil, b æe sil b ɑe sil, b æe si...  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
