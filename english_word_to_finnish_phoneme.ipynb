{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Notebook to generate Finnish phoneme representation of English words, for generating training data for sIAk model. \n",
    "The code is written intending to be a script. and a notebook based on the need.\n",
    "\n",
    "- *Inputs*: \n",
    "    - Wordlist, text file with 1 word/sentence per line.\n",
    "    - English Dict, word, phoneme representation form. *[hard coded for en_uk].\n",
    "    - Finnish dict,\n",
    "    - Eng to Global map. Pickle of a dictionary with {phoneme -> phoneme rep}\n",
    "    - Finnish to Global Map.\n",
    "    - Global phone distances.\n",
    "    \n",
    "\n",
    "- *Outputs*:\n",
    "- *HyperParameters*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " Code to Run the below file as a script to generate english words to generate based on different distance \n",
    " metrics and english and finnihs dictionaries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Outputs the Finnish Phoneme representation of the english words')\n",
    "\n",
    "parser.add_argument(\"word_list\",help=\"Path to the text file to be converted to Finnish phonetic symbols\",type=str)\n",
    "parser.add_argument(\"-ed\",\"--english_dict\",default=\"dict/en_uk_dict.txt\")\n",
    "parser.add_argument('--eng_to_global_map', default='../mappings/en_uk_ph_dist_phones_map.pkl',\n",
    "                    help=\"Path to the english to global phoneme dictionary mapping\", type=str)\n",
    "parser.add_argument('--fin_to_global_map', default='../mappings/fin_2_global_phones_map.pkl',\n",
    "                    help=\"Path to the finnish to global phoneme dictionary mapping\", type=str)\n",
    "parser.add_argument('--global_phone_distances', default='../mappings/global_phone_distances.pkl',\n",
    "                    help=\"Path to the english to global phoneme dictionary mapping\", type=str)\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_word_2_us_en_rep(sentence):\n",
    "    '''\n",
    "    inputs:\n",
    "    sentence: (str) Sentence which needs to be represented in phones.\n",
    "    outputs:\n",
    "    transcripts (str)['ph ph ph'] Phoneme representation of sentence.\n",
    "    '''\n",
    "    \n",
    "    # Save transcript for each word in the sentence in a list transcripts.\n",
    "    words = sentence.split(' ')    \n",
    "    transcripts = []\n",
    "    for word in words:\n",
    "        if word not in en_uk_dict.keys():\n",
    "            return ''\n",
    "        else:\n",
    "            transcripts.append(en_uk_dict[word])\n",
    "    \n",
    "    #Take the transcripts in the transcript list and make a phoneme representation.\n",
    "    # Taking care if it's a single word or a sentence.\n",
    "    \n",
    "    transcript = ''\n",
    "    if len(transcripts) == 1:\n",
    "        transcript += transcripts[0]\n",
    "    else:\n",
    "        for i in transcripts:\n",
    "            transcript += i \n",
    "            transcript += \" sil \"\n",
    "\n",
    "    return transcript.rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eng_ph_2_global_ph(english_ph_transcript):\n",
    "    '''\n",
    "    input: \n",
    "    english_ph_transcript - English phone transcripts from mapping file. 'ph ph ph ...'\n",
    "    output: \n",
    "    global_ph_transcript: 'ph ph ph ...'\n",
    "    Hyperparameter: eng_to_global_map.\n",
    "    '''\n",
    "    global_ph_transcript = ''\n",
    "    for phone in english_ph_transcript.split(\" \"):\n",
    "        global_ph_transcript += eng_to_global_map[phone]\n",
    "        global_ph_transcript += ' '\n",
    "    \n",
    "    return global_ph_transcript.rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def glob_transcript_2_fin_nearest(transcript):\n",
    "    '''Returns the nearest finnish phoneme to each of the global transcript\n",
    "       Input: Global phoneme representation seperated by a space\n",
    "       Output: Finnish phoneme representation seperated by space.\n",
    "    '''\n",
    "    fin_transcript = ''\n",
    "    for phone in transcript.split(\" \"):\n",
    "         \n",
    "        if type(global_2_fin_map[phone]) is list:\n",
    "            fin_transcript += global_2_fin_map[phone][0]\n",
    "        else:\n",
    "            fin_transcript += global_2_fin_map[phone]       \n",
    "        \n",
    "        fin_transcript += ' '\n",
    "    return fin_transcript.rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adding the words/sentences to be translated to a **mapping** file, where the further mappings can be representated.\n",
    "mapping = pd.read_csv('eval_text/words.txt',header=None,names=['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'English Phoneme Representation samples:'\n",
      "          en_rep\n",
      "word            \n",
      "'cause    kʰ ɒ z\n",
      "'cause    kʰ ə z\n",
      "'dominee     spn\n",
      "'em          ə m\n",
      "'n            n̩\n",
      "'The Dataframe after mapping english words to phonemes:'\n",
      "  sentence     eng_transcript  no_transcript_flag\n",
      "0     girl             g ɜː ɫ               False\n",
      "1    hello           h ɛ l əʊ               False\n",
      "2     book              b ʊ k               False\n",
      "3    learn             l ɜː n               False\n",
      "4  bye bye  b aɪ sil b aɪ sil               False\n"
     ]
    }
   ],
   "source": [
    "# Reading the english dictionary. \n",
    "# English Dictionary should be a text file with each line representeda s follows\n",
    "# language_dialect_word [\\t tab] phone[space]phone[space]...\n",
    "\n",
    "en_uk_dict = pd.read_csv('dict/en_uk_dict.txt',header=None,names=['word','en_rep'],sep='\\t')#,index_col=['word'])\n",
    "\n",
    "#Removing 'language_dialect_' part\n",
    "word_after_remov_en_uk = en_uk_dict.word.apply(lambda en_uk_word: en_uk_word.split('_')[-1])\n",
    "en_uk_dict.set_index(word_after_remov_en_uk,inplace=True)\n",
    "en_uk_dict.drop('word',axis=1,inplace=True)\n",
    "pprint('English Phoneme Representation samples:')\n",
    "pprint(en_uk_dict.head())\n",
    "\n",
    "en_uk_dict = en_uk_dict.to_dict()['en_rep']\n",
    "#Add the English phoneme representation to the mapping dataframe            \n",
    "mapping =mapping.assign(eng_transcript= mapping.sentence.apply(map_word_2_us_en_rep))\n",
    "mapping = mapping.assign(no_transcript_flag=(mapping.eng_transcript==''))\n",
    "pprint('The Dataframe after mapping english words to phonemes:')\n",
    "pprint(mapping.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the English to Global rep and make the mapping in the file.\n",
    "\n",
    "\n",
    "'''Reading the pprint english to global map dictionary\n",
    "{'': '',\n",
    " 'ɒ': 'ɒ',\n",
    " .\n",
    " .\n",
    " .\n",
    " }\n",
    "'''\n",
    "\n",
    "eng_to_global_map = pd.read_pickle('mappings/en_uk_ph_dist_phones_map.pkl')\n",
    "#eng_to_global_map = pd.read_pickle(args.eng_to_global_map)\n",
    "\n",
    "#Writing the map back to file for reference.\n",
    "'''\n",
    "with open('mappings/eng_to_global_map.txt', 'w') as f:\n",
    "    for key, value in eng_to_global_map.items():\n",
    "        f.write(key)\n",
    "        f.write('    ')\n",
    "        f.write(value)\n",
    "        f.write(\"\\n\")\n",
    "'''\n",
    "\n",
    "mapping = mapping.assign(global_transcript = mapping.eng_transcript.apply(eng_ph_2_global_ph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global_phone_2_text = mapping.set_index('sentence')\n",
    "global_phone_2_text = global_phone_2_text[['global_transcript']]\n",
    "\n",
    "for speaker in [555,585,600]:\n",
    "    global_phone_2_text = global_phone_2_text.assign(speaker_id = len(global_phone_2_text)*[speaker])\n",
    "    global_phone_2_text.to_csv('eval_text/eng_game_words_phone_rep_{}.txt'.format(speaker), sep='|', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the Fin to Global Map and compute Global to Finnish Map.\n",
    "\n",
    "fin_to_global_map = pd.read_pickle('mappings/fin_2_global_phones_map.pkl')\n",
    "#fin_to_global_map = pd.read_pickle(args.fin_to_global_map)\n",
    "global_2_fin_map = dict([[value,key] for key,value in fin_to_global_map.items()])\n",
    "\n",
    "global_phone_dist = pd.read_pickle('mappings/phone_distances.pickle')\n",
    "\n",
    "global_ph = global_phone_dist['phones']\n",
    "global_ph_dist = global_phone_dist['phone_distances']\n",
    "\n",
    "global_ph_dist = pd.DataFrame(data=global_ph_dist,index=global_ph.values(),columns=global_ph.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of          sentence             eng_transcript  no_transcript_flag  \\\n",
      "0            girl                     g ɜː ɫ               False   \n",
      "1           hello                   h ɛ l əʊ               False   \n",
      "2            book                      b ʊ k               False   \n",
      "3           learn                     l ɜː n               False   \n",
      "4         bye bye          b aɪ sil b aɪ sil               False   \n",
      "5         come on          k ʌ m sil ɒ n sil               False   \n",
      "6            leaf                     l iː f               False   \n",
      "7           plant                 p l ɑː n t               False   \n",
      "8            tree                     t ɹ iː               False   \n",
      "9            rock                      ɹ ɒ k               False   \n",
      "10           life                     l aɪ f               False   \n",
      "11          wrong                      ɹ ɒ ŋ               False   \n",
      "12          round                   ɹ aʊ n d               False   \n",
      "13            wet                      w ɛ t               False   \n",
      "14           high                       h aɪ               False   \n",
      "15         school                   s k uː ɫ               False   \n",
      "16           make                     m eɪ k               False   \n",
      "17           lick                      l ɪ k               False   \n",
      "18           milk                    m ɪ ɫ k               False   \n",
      "19           more                       m ɔː               False   \n",
      "20          spoon                   s p uː n               False   \n",
      "21          write                     ɹ aɪ t               False   \n",
      "22            boy                       b ɔɪ               False   \n",
      "23           lake                     l eɪ k               False   \n",
      "24          light                     l aɪ t               False   \n",
      "25          sorry                   s ɒ ɹ iː               False   \n",
      "26            air                         ɛə               False   \n",
      "27           moon                     m uː n               False   \n",
      "28            low                       l əʊ               False   \n",
      "29            sun                      s ʌ n               False   \n",
      "..            ...                        ...                 ...   \n",
      "281         drink                  d ɹ ɪ ŋ k               False   \n",
      "282          chin                     tʃ ɪ n               False   \n",
      "283          good                      g ʊ d               False   \n",
      "284           dog                      d ɒ g               False   \n",
      "285          cook                      k ʊ k               False   \n",
      "286         berry                   b ɛ ɹ iː               False   \n",
      "287           old                     əʊ ɫ d               False   \n",
      "288        butter                    b ʌ t ə               False   \n",
      "289           eat                       iː t               False   \n",
      "290          dark                     d ɑː k               False   \n",
      "291           cut                      k ʌ t               False   \n",
      "292      cucumber           k j uː k ʌ m b ə               False   \n",
      "293        cheese                    tʃ iː z               False   \n",
      "294            it                        ɪ t               False   \n",
      "295          bear                       b ɛə               False   \n",
      "296           owl                       aʊ ɫ               False   \n",
      "297        potato            pʰ ə tʰ eɪ t əʊ               False   \n",
      "298           yet                      j ɛ t               False   \n",
      "299         grass                   g ɹ ɑː s               False   \n",
      "300          baby                  b eɪ b iː               False   \n",
      "301          pear                      pʰ ɛə               False   \n",
      "302        carpet                kʰ ɑː p ɪ t               False   \n",
      "303           why                       w aɪ               False   \n",
      "304         lemon                  l ɛ m ə n               False   \n",
      "305        cherry                  tʃ ɛ ɹ iː               False   \n",
      "306          lamp                    l a m p               False   \n",
      "307  good evening  g ʊ d sil iː v n̩ ɪ ŋ sil               False   \n",
      "308         woman                  w ʊ m ə n               False   \n",
      "309     come here        k ʌ m sil h ɪə  sil               False   \n",
      "310       you are             j ə sil ə  sil               False   \n",
      "\n",
      "             global_transcript       fin_transcript  \n",
      "0                        g ɜ ɫ               gː i l  \n",
      "1                     h ɛ l əʊ              h i l y  \n",
      "2                        b ʊ k                b y k  \n",
      "3                        l ɜ n                l i n  \n",
      "4            b aɪ sil b aɪ sil          b æe   b æe  \n",
      "5            k ʌ m sil ɒ n sil         k ɑ mː   ɑ n  \n",
      "6                       l iː f               l iː f  \n",
      "7                   p l ɑː n t           p l ɑː n t  \n",
      "8                       t ɹ iː              t rː iː  \n",
      "9                        ɹ ɒ k               rː ɑ k  \n",
      "10                      l aɪ f               l æe f  \n",
      "11                       ɹ ɒ ŋ               rː ɑ ŋ  \n",
      "12                    ɹ aʊ n d            rː ɑu n d  \n",
      "13                       w ɛ t                v i t  \n",
      "14                        h aɪ                 h æe  \n",
      "15                    s k uː ɫ             s k uː l  \n",
      "16                      m eɪ k               mː e k  \n",
      "17                       l ɪ k                l e k  \n",
      "18                     m ɪ ɫ k             mː e l k  \n",
      "19                         m ɔ                 mː o  \n",
      "20                    s p uː n             s p uː n  \n",
      "21                      ɹ aɪ t              rː æe t  \n",
      "22                        b ɔɪ                 b oi  \n",
      "23                      l eɪ k                l e k  \n",
      "24                      l aɪ t               l æe t  \n",
      "25                    s ɒ ɹ iː            s ɑ rː iː  \n",
      "26                          ɛə                    i  \n",
      "27                      m uː n              mː uː n  \n",
      "28                        l əʊ                  l y  \n",
      "29                       s ʌ n                s ɑ n  \n",
      "..                         ...                  ...  \n",
      "281                  d ɹ ɪ ŋ k           d rː e ŋ k  \n",
      "282                     tʃ ɪ n                s e n  \n",
      "283                      g ʊ d               gː y d  \n",
      "284                      d ɒ g               d ɑ gː  \n",
      "285                      k ʊ k                k y k  \n",
      "286                   b ɛ ɹ iː            b i rː iː  \n",
      "287                     əʊ ɫ d                y l d  \n",
      "288                    b ʌ t ə              b ɑ t y  \n",
      "289                       iː t                 iː t  \n",
      "290                     d ɑː k               d ɑː k  \n",
      "291                      k ʌ t                k ɑ t  \n",
      "292           k j uː k ʌ m b ə    k j uː k ɑ mː b y  \n",
      "293                    tʃ iː z               s iː s  \n",
      "294                        ɪ t                  e t  \n",
      "295                       b ɛə                  b i  \n",
      "296                       aʊ ɫ                 ɑu l  \n",
      "297            pʰ ə tʰ eɪ t əʊ        p y tsː e t y  \n",
      "298                      j ɛ t                j i t  \n",
      "299                   g ɹ ɑː s           gː rː ɑː s  \n",
      "300                  b eɪ b iː             b e b iː  \n",
      "301                      pʰ ɛə                  p i  \n",
      "302                kʰ ɑː p ɪ t           k ɑː p e t  \n",
      "303                       w aɪ                 v æe  \n",
      "304                  l ɛ m ə n           l i mː y n  \n",
      "305                  tʃ ɛ ɹ iː            s i rː iː  \n",
      "306                    l a m p             l æ mː p  \n",
      "307  g ʊ d sil iː v n̩ ɪ ŋ sil  gː y d   iː v n e ŋ  \n",
      "308                  w ʊ m ə n           v y mː y n  \n",
      "309     k ʌ m sil h ɪə sil sil        k ɑ mː   h ie  \n",
      "310          j ə sil ə sil sil              j y   y  \n",
      "\n",
      "[311 rows x 5 columns]>\n"
     ]
    }
   ],
   "source": [
    "distance_2_fin = global_ph_dist.loc[global_2_fin_map.keys()]\n",
    "\n",
    "for ph in global_ph.values():\n",
    "    if ph not in global_2_fin_map.keys():\n",
    "        three_nearest_phones = list(distance_2_fin[ph].sort_values()[:3].index)\n",
    "        global_2_fin_map[ph] = three_nearest_phones\n",
    "global_2_fin_map['w'] = 'v'\n",
    "global_2_fin_map['z'] = 's'\n",
    "\n",
    "mapping = mapping.assign(fin_transcript=mapping.global_transcript.apply(glob_transcript_2_fin_nearest))\n",
    "pprint(mapping.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>eng_transcript</th>\n",
       "      <th>no_transcript_flag</th>\n",
       "      <th>global_transcript</th>\n",
       "      <th>fin_transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>girl</td>\n",
       "      <td>g ɜː ɫ</td>\n",
       "      <td>False</td>\n",
       "      <td>g ɜ ɫ</td>\n",
       "      <td>gː i l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hello</td>\n",
       "      <td>h ɛ l əʊ</td>\n",
       "      <td>False</td>\n",
       "      <td>h ɛ l əʊ</td>\n",
       "      <td>h i l y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>book</td>\n",
       "      <td>b ʊ k</td>\n",
       "      <td>False</td>\n",
       "      <td>b ʊ k</td>\n",
       "      <td>b y k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>learn</td>\n",
       "      <td>l ɜː n</td>\n",
       "      <td>False</td>\n",
       "      <td>l ɜ n</td>\n",
       "      <td>l i n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bye bye</td>\n",
       "      <td>b aɪ sil b aɪ sil</td>\n",
       "      <td>False</td>\n",
       "      <td>b aɪ sil b aɪ sil</td>\n",
       "      <td>b æe   b æe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentence     eng_transcript  no_transcript_flag  global_transcript  \\\n",
       "0     girl             g ɜː ɫ               False              g ɜ ɫ   \n",
       "1    hello           h ɛ l əʊ               False           h ɛ l əʊ   \n",
       "2     book              b ʊ k               False              b ʊ k   \n",
       "3    learn             l ɜː n               False              l ɜ n   \n",
       "4  bye bye  b aɪ sil b aɪ sil               False  b aɪ sil b aɪ sil   \n",
       "\n",
       "  fin_transcript  \n",
       "0         gː i l  \n",
       "1        h i l y  \n",
       "2          b y k  \n",
       "3          l i n  \n",
       "4    b æe   b æe  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['d', 'l', 'n'], dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance_2_fin['z'].sort_values()[:3].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code looking only at the global symbols which are used in representing english pronunciation\n",
    "# Checking if all the mappings make sense.\n",
    "\n",
    "global_phones_of_interest = list(eng_to_global_map.values())\n",
    "#for ph in global_phones_of_interest:\n",
    "glob_2_fin_of_interest = {ph:global_2_fin_map[ph] for ph in global_phones_of_interest}\n",
    "#pprint(glob_2_fin_of_interest)\n",
    "\n",
    "\n",
    "mapping[(mapping.global_transcript.apply(lambda x: ' ʃ ' in x))]\n",
    "\n",
    "# Loading the finnish dictionary to verify the mapping is fine.\n",
    "fin_dict = pd.read_csv('dict/fi_child_ipa_dict.txt',header=None,names=['word','fin_rep'],sep='\\t',index_col=['word'])\n",
    "#fin_dict[fin_dict.fin_rep.apply(lambda rep: ' v ' in rep)]\n",
    "#fin_dict = fin_dict.to_dict()['fin_rep']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def phone_sentences(sentence):\n",
    "    sentence = sentence.replace(\"  \",\"<sil>\")\n",
    "    sentence = sentence.replace(\" \",\"\")\n",
    "    sentence = sentence.replace(\"<sil>\",\" \")\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mappings_2_text(index='all',speakers=[600], name='eng_game_words'):\n",
    "    '''\n",
    "    Input : \n",
    "    Index - Index of the the mapping file to be written into a evaluation file.\n",
    "                Default : all the words\n",
    "    speakers - List of speakers the be generated by tacotron.\n",
    "    name - Name of the output text file\n",
    "    \n",
    "    Output:\n",
    "    None, Saves the file in the eval_text/folder. \n",
    "    '''\n",
    "    if index == 'all':\n",
    "        transcript_2_text = mapping[['sentence','fin_transcript']]\n",
    "    else:\n",
    "        transcript_2_text = mapping.iloc[index][['sentence','fin_transcript']]\n",
    "\n",
    "    transcript_2_text.set_index('sentence',inplace=True)\n",
    "    transcript_2_text = transcript_2_text.assign(\n",
    "                                fin_transcript=transcript_2_text.fin_transcript.apply(phone_sentences))\n",
    "    for speaker in speakers:\n",
    "        transcript_2_text = transcript_2_text.assign(speaker_id = len(transcript_2_text)*[speaker])\n",
    "        \n",
    "        from pathlib import Path\n",
    "        my_file = Path('eval_text/{}_{}.txt'.format(name,speaker))\n",
    "        \n",
    "        if my_file.is_file():\n",
    "            print('eval_text/{}_{}.txt already exists; not writing the file'.format(name,speaker))\n",
    "        else:    \n",
    "            transcript_2_text.to_csv('eval_text/{}_{}.txt'.format(name,speaker), sep='|', header=False)\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mapping.to_excel('mappings/word_wmappings_new.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "with open('mappings/global_to_fin_distance_map.txt', 'w') as f:\n",
    "    for key, value in global_2_fin_map.items():\n",
    "        f.write(key)\n",
    "        f.write('    ')\n",
    "        f.write(str(value))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "with open('mappings/global_to_fin_map.txt', 'w') as f:\n",
    "    for key, value in global_2_fin_map.items():\n",
    "        f.write(key)\n",
    "        f.write('    ')\n",
    "        f.write(value)\n",
    "        f.write(\"\\n\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_text/eng_Fin_same_rep_590.txt already exists; not writing the file\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Savings words to genrate which have same phonemic representation in Finnish and English.\n",
    "\n",
    "indexes = mapping[mapping.eng_transcript == mapping.fin_transcript].index\n",
    "np.random.seed(2)\n",
    "speakers = np.random.randint(low = 550, high =601, size=10)\n",
    "mappings_2_text(index=indexes, speakers=speakers,name='eng_Fin_same_rep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Savings words to genrate which have same phonemic representation in Finnish and English.\n",
    "\n",
    "indexes = mapping[mapping.eng_transcript == mapping.fin_transcript].index\n",
    "np.random.seed(2)\n",
    "speakers = np.random.randint(low = 1, high =550, size=10)\n",
    "\n",
    "mappings_2_text(index=indexes, speakers=speakers,name='adult_eng_Fin_same_rep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = mapping.head()\n",
    "\n",
    "a = d.fin_transcript\n",
    "a.aplly()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
