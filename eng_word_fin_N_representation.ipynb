{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Notebook to generate 10,20, 50 Finnish phoneme representation for each English words in the game data.\n",
    "Created from the base: english_word_to_finnish_phoneme.ipynb.\n",
    "\n",
    "Author: Sujith Padaru\n",
    "- *Inputs*: \n",
    "    - Game words\n",
    "    - English Dict, word, phoneme representation form. *[hard coded for en_uk].\n",
    "    - Finnish dict,\n",
    "    - Eng to Global map. Pickle of a dictionary with {phoneme -> phoneme rep}\n",
    "    - Finnish to Global Map.\n",
    "    - Global phone distances.\n",
    "    \n",
    "\n",
    "- *Outputs*: \n",
    "    - n finnish phonetical representation for each word.\n",
    "- *HyperParameters*:\n",
    "    - n number of samples to generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from itertools import product\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " Code to Run the below file as a script to generate english words to generate based on different distance \n",
    " metrics and english and finnihs dictionaries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_eng_sentence_2_en_uk_phone_rep(sentence):\n",
    "    '''\n",
    "    inputs:\n",
    "    sentence: (str) Sentence which needs to be represented in phones.\n",
    "    outputs:\n",
    "    transcripts (str)['ph ph ph'] Phoneme representation of sentence.\n",
    "    '''\n",
    "    \n",
    "    # Save transcript for each word in the sentence in a list transcripts.\n",
    "    words = sentence.split(' ')    \n",
    "    word_transcripts = []\n",
    "    for word in words:\n",
    "        if word not in en_uk_dict.keys():\n",
    "            return ''\n",
    "        else:\n",
    "            word_transcripts.append(en_uk_dict[word])\n",
    "    \n",
    "    #Take the transcripts in the transcript list and make a phoneme representation.\n",
    "    # Taking care if it's a single word or a sentence.\n",
    "    \n",
    "    sentence_transcript = ''\n",
    "    if len(word_transcripts) == 1:\n",
    "        sentence_transcript += word_transcripts[0]\n",
    "    else:\n",
    "        for i in word_transcripts:\n",
    "            sentence_transcript += i \n",
    "            sentence_transcript += \" sil \"\n",
    "\n",
    "    return sentence_transcript.rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eng_ph_2_global_ph(english_ph_transcript):\n",
    "    '''\n",
    "    input: \n",
    "    english_ph_transcript - English phone transcripts from mapping file. 'ph ph ph ...'\n",
    "    output: \n",
    "    global_ph_transcript: 'ph ph ph ...'\n",
    "    Hyperparameter: eng_to_global_map.\n",
    "    '''\n",
    "    global_ph_transcript = ''\n",
    "    for phone in english_ph_transcript.split(\" \"):\n",
    "        global_ph_transcript += eng_to_global_map[phone]\n",
    "        global_ph_transcript += ' '\n",
    "    \n",
    "    return global_ph_transcript.rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def glob_transcript_2_fin_nearest(transcript):\n",
    "    '''Returns the nearest finnish phoneme to each of the global transcript\n",
    "       Input: Global phoneme representation seperated by a space\n",
    "       Output: Finnish phoneme representation seperated by space.\n",
    "    '''\n",
    "    fin_transcript = ''\n",
    "    for phone in transcript.split(\" \"):\n",
    "         \n",
    "        if type(global_2_fin_map[phone]) is list:\n",
    "            fin_transcript += global_2_fin_map[phone][0]\n",
    "        else:\n",
    "            fin_transcript += global_2_fin_map[phone]       \n",
    "        \n",
    "        fin_transcript += ' '\n",
    "    return fin_transcript.rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glob_transcript_2_N_fin(transcript):\n",
    "    '''Returns the nearest finnish phoneme to each of the global transcript\n",
    "       Input: Global phoneme representation seperated by a space\n",
    "       Output: Finnish phoneme representation seperated by space.\n",
    "    '''\n",
    "    \n",
    "    phone_maps = []\n",
    "    for phone in transcript.split(\" \"):\n",
    "        if phone == 'sil':\n",
    "            phone_maps.append(['sil'])\n",
    "        else:\n",
    "            phone_maps.append(global_2_fin_map[phone])\n",
    "    \n",
    "    list_of_trans = list(product(*phone_maps))    \n",
    "    list_of_trans = [\" \".join(list(trans)) for trans in list_of_trans]\n",
    "    return list_of_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def phone_sentences(sentence):\n",
    "    sentence = sentence.replace(\"  \",\"<sil>\")\n",
    "    sentence = sentence.replace(\" \",\"\")\n",
    "    sentence = sentence.replace(\"<sil>\",\" \")\n",
    "    return sentence\n",
    "\n",
    "def mappings_2_text(index='all',speakers=[600], name='eng_game_words'):\n",
    "    '''\n",
    "    Input : \n",
    "    Index - Index of the the mapping file to be written into a evaluation file.\n",
    "                Default : all the words\n",
    "    speakers - List of speakers the be generated by tacotron.\n",
    "    name - Name of the output text file\n",
    "    \n",
    "    Output:\n",
    "    None, Saves the file in the eval_text/folder. \n",
    "    '''\n",
    "    if index == 'all':\n",
    "        transcript_2_text = mapping[['sentence','fin_transcript']]\n",
    "    else:\n",
    "        transcript_2_text = mapping.iloc[index][['sentence','fin_transcript']]\n",
    "\n",
    "    transcript_2_text.set_index('sentence',inplace=True)\n",
    "    transcript_2_text = transcript_2_text.assign(\n",
    "                                fin_transcript=transcript_2_text.fin_transcript.apply(phone_sentences))\n",
    "    for speaker in speakers:\n",
    "        transcript_2_text = transcript_2_text.assign(speaker_id = len(transcript_2_text)*[speaker])\n",
    "        \n",
    "        my_file = Path('eval_text/{}_{}.txt'.format(name,speaker))\n",
    "        \n",
    "        if my_file.is_file():\n",
    "            print('eval_text/{}_{}.txt already exists; not writing the file'.format(name,speaker))\n",
    "        else:    \n",
    "            transcript_2_text.to_csv('eval_text/{}_{}.txt'.format(name,speaker), sep='|', header=False)\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def mappings_2_text_N(N=20, index='all', speakers=[600], name='eng_game_words'):\n",
    "    '''\n",
    "    Input : \n",
    "    N : Number of alternate Finnish phonemic representation for each game word.\n",
    "    Index - Index of the the mapping file to be written into a evaluation file.\n",
    "                Default : all the words\n",
    "    speakers - List of speakers the be generated by tacotron.\n",
    "    name - Name of the output text file\n",
    "    \n",
    "    Output:\n",
    "    None, Saves the file in the eval_text/folder. \n",
    "    '''\n",
    "    if index == 'all':\n",
    "        transcript_2_text = mapping[['sentence','all_fin_transcripts']]\n",
    "    else:\n",
    "        transcript_2_text = mapping.iloc[index][['sentence','all_fin_transcripts']]\n",
    "\n",
    "    transcript_2_text.set_index('sentence',inplace=True)\n",
    "    \n",
    "    dfs = []\n",
    "    for sentence, all_fin_transcripts in transcript_2_text.iterrows():\n",
    "        list_of_trans = all_fin_transcripts.values[0]\n",
    "        number_of_trans = len(list_of_trans)\n",
    "\n",
    "        if number_of_trans > 20:\n",
    "            np.random.seed(0)\n",
    "            transcripts = np.random.choice(list_of_trans, size=20, replace=False)\n",
    "            df = pd.DataFrame(transcripts)\n",
    "            df = df.assign(sentence = 20*[sentence])\n",
    "        else:\n",
    "            df = pd.DataFrame(list_of_trans)\n",
    "            df = df.assign(sentence = number_of_trans*[sentence])\n",
    "        dfs.append(df)\n",
    "    \n",
    "    transcript_2_text = pd.concat(dfs)\n",
    "    transcript_2_text.set_index('sentence',inplace=True)\n",
    "    \n",
    "    for speaker in speakers:\n",
    "        transcript_2_text = transcript_2_text.assign(speaker_id = len(transcript_2_text)*[speaker])\n",
    "        \n",
    "        my_file = Path('eval_text/{}_{}.txt'.format(name,speaker))\n",
    "        \n",
    "        if my_file.is_file():\n",
    "            print('eval_text/{}_{}.txt already exists; not writing the file'.format(name,speaker))\n",
    "        else:    \n",
    "            transcript_2_text.to_csv('eval_text/{}_spk_{}.txt'.format(name,speaker), sep='|', header=False)\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## __main__():\n",
    "Read the Game Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Outputs the Finnish Phoneme representation of the english words')\n",
    "\n",
    "parser.add_argument(\"word_list\",help=\"Path to the text file to be converted to Finnish phonetic symbols\",type=str)\n",
    "parser.add_argument(\"-ed\",\"--english_dict\",default=\"dict/en_uk_dict.txt\")\n",
    "parser.add_argument('--eng_to_global_map', default='../mappings/en_uk_ph_dist_phones_map.pkl',\n",
    "                    help=\"Path to the english to global phoneme dictionary mapping\", type=str)\n",
    "parser.add_argument('--fin_to_global_map', default='../mappings/fin_2_global_phones_map.pkl',\n",
    "                    help=\"Path to the finnish to global phoneme dictionary mapping\", type=str)\n",
    "parser.add_argument('--global_phone_distances', default='../mappings/global_phone_distances.pkl',\n",
    "                    help=\"Path to the english to global phoneme dictionary mapping\", type=str)\n",
    "args = parser.parse_args()\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Adding the words/sentences to be translated to a **mapping** file, where the further mappings can be representated.\n",
    "mapping = pd.read_csv('eval_text/words.txt',header=None,names=['sentence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Read the English Dictionary \n",
    "- preprocess it\n",
    "- Convert english word rep to eng phoneme rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'English Phoneme Representation samples:'\n",
      "          en_rep\n",
      "word            \n",
      "'cause    kʰ ɒ z\n",
      "'cause    kʰ ə z\n",
      "'dominee     spn\n",
      "'em          ə m\n",
      "'n            n̩\n",
      "'The Dataframe after mapping english words to phonemes:'\n",
      "  sentence     eng_transcript  no_transcript_flag\n",
      "0     girl             g ɜː ɫ               False\n",
      "1    hello           h ɛ l əʊ               False\n",
      "2     book              b ʊ k               False\n",
      "3    learn             l ɜː n               False\n",
      "4  bye bye  b aɪ sil b aɪ sil               False\n"
     ]
    }
   ],
   "source": [
    "# Reading and preprocessing the english dictionary. \n",
    "# English Dictionary should be a text file with each line representeda s follows\n",
    "# language_dialect_word [\\t tab] phone[space]phone[space]...\n",
    "\n",
    "en_uk_dict = pd.read_csv('dict/en_uk_dict.txt',header=None,names=['word','en_rep'],sep='\\t')#,index_col=['word'])\n",
    "\n",
    "#Removing 'language_dialect_' part\n",
    "word_after_remov_en_uk = en_uk_dict.word.apply(lambda en_uk_word: en_uk_word.split('_')[-1])\n",
    "en_uk_dict.set_index(word_after_remov_en_uk,inplace=True)\n",
    "en_uk_dict.drop('word',axis=1,inplace=True)\n",
    "pprint('English Phoneme Representation samples:')\n",
    "pprint(en_uk_dict.head())\n",
    "\n",
    "en_uk_dict = en_uk_dict.to_dict()['en_rep']\n",
    "#Add the English phoneme representation to the mapping dataframe            \n",
    "mapping =mapping.assign(eng_transcript= mapping.sentence.apply(map_eng_sentence_2_en_uk_phone_rep))\n",
    "mapping = mapping.assign(no_transcript_flag=(mapping.eng_transcript==''))\n",
    "pprint('The Dataframe after mapping english words to phonemes:')\n",
    "pprint(mapping.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Read English phoneme to Global Phoneme Map\n",
    "- Eng phoneme rep to Global Phoneme rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the English to Global rep and make the mapping in the file.\n",
    "\n",
    "\n",
    "'''Reading the pprint english to global map dictionary\n",
    "{'': '',\n",
    " 'ɒ': 'ɒ',\n",
    " .\n",
    " .\n",
    " .\n",
    " }\n",
    "'''\n",
    "\n",
    "eng_to_global_map = pd.read_pickle('mappings/en_uk_ph_dist_phones_map.pkl')\n",
    "#eng_to_global_map = pd.read_pickle(args.eng_to_global_map)\n",
    "\n",
    "\n",
    "mapping = mapping.assign(global_transcript = mapping.eng_transcript.apply(eng_ph_2_global_ph))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Read Finnish phoneme map to Global Map\n",
    "- Read Global Phone Distance\n",
    "- Infer Global phone to Finnish Phone Map\n",
    "- Find Finnish Phoneme Rep from Global Rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Fin to Global Map and compute Global to Finnish Map.\n",
    "\n",
    "fin_to_global_map = pd.read_pickle('mappings/fin_2_global_phones_map.pkl')\n",
    "global_2_fin_map = dict([[value,key] for key,value in fin_to_global_map.items()])\n",
    "\n",
    "global_phone_dist = pd.read_pickle('mappings/phone_distances.pickle')\n",
    "\n",
    "global_ph = global_phone_dist['phones']\n",
    "global_ph_dist = global_phone_dist['phone_distances']\n",
    "\n",
    "global_ph_dist = pd.DataFrame(data=global_ph_dist,index=global_ph.values(),columns=global_ph.values())\n",
    "\n",
    "distance_2_fin = global_ph_dist.loc[global_2_fin_map.keys()]\n",
    "\n",
    "for ph in global_ph.values():\n",
    "    three_nearest_phones = list(distance_2_fin[ph].sort_values()[:3].index)\n",
    "    global_2_fin_map[ph] = three_nearest_phones\n",
    "\n",
    "\n",
    "global_2_fin_map['w'] = np.concatenate([global_2_fin_map['w'][:2],['v']])\n",
    "global_2_fin_map['w'] = list(global_2_fin_map['w'])\n",
    "global_2_fin_map['z'] = np.concatenate([global_2_fin_map['z'][:2],['s']])\n",
    "global_2_fin_map['z'] = list(global_2_fin_map['z'])\n",
    "\n",
    "mapping = mapping.assign(fin_transcript=mapping.global_transcript.apply(glob_transcript_2_fin_nearest))\n",
    "pprint(mapping.head(5))\n",
    "\n",
    "\n",
    "mapping = mapping.assign(all_fin_transcripts =\n",
    "                         mapping.global_transcript.apply(glob_transcript_2_N_fin))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create the Dataframe to save the evaluation file.\n",
    "- Save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/teamwork/t40511_asr/Modules/opt/anaconda3/lib/python3.5/site-packages/pandas/core/indexes/base.py:3726: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = op(self.values, np.asarray(other))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating 20 fin reps for 5 random words with speaker, 600, 555, 567 and 57, 258 \n",
    "\n",
    "indexes = mapping.sample(5).index\n",
    "rand_spks = [600, 555, 567, 57, 258]\n",
    "mappings_2_text_N(index=indexes, speakers=rand_spks, name='5_words_20_rep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>eng_transcript</th>\n",
       "      <th>no_transcript_flag</th>\n",
       "      <th>global_transcript</th>\n",
       "      <th>fin_transcript</th>\n",
       "      <th>all_fin_transcripts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>girl</td>\n",
       "      <td>g ɜː ɫ</td>\n",
       "      <td>False</td>\n",
       "      <td>g ɜ ɫ</td>\n",
       "      <td>g i l</td>\n",
       "      <td>[g i l, g i lː, g i rː, g æ l, g æ lː, g æ rː,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hello</td>\n",
       "      <td>h ɛ l əʊ</td>\n",
       "      <td>False</td>\n",
       "      <td>h ɛ l əʊ</td>\n",
       "      <td>h i l ou</td>\n",
       "      <td>[h i l ou, h i l u, h i l y, h i lː ou, h i lː...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>book</td>\n",
       "      <td>b ʊ k</td>\n",
       "      <td>False</td>\n",
       "      <td>b ʊ k</td>\n",
       "      <td>b u k</td>\n",
       "      <td>[b u k, b u kː, b u p, b y k, b y kː, b y p, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>learn</td>\n",
       "      <td>l ɜː n</td>\n",
       "      <td>False</td>\n",
       "      <td>l ɜ n</td>\n",
       "      <td>l i n</td>\n",
       "      <td>[l i n, l i nː, l i rː, l æ n, l æ nː, l æ rː,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bye bye</td>\n",
       "      <td>b aɪ sil b aɪ sil</td>\n",
       "      <td>False</td>\n",
       "      <td>b aɪ sil b aɪ sil</td>\n",
       "      <td>b æe sil b æe sil</td>\n",
       "      <td>[b æe sil b æe sil, b æe sil b ɑe sil, b æe si...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentence     eng_transcript  no_transcript_flag  global_transcript  \\\n",
       "0     girl             g ɜː ɫ               False              g ɜ ɫ   \n",
       "1    hello           h ɛ l əʊ               False           h ɛ l əʊ   \n",
       "2     book              b ʊ k               False              b ʊ k   \n",
       "3    learn             l ɜː n               False              l ɜ n   \n",
       "4  bye bye  b aɪ sil b aɪ sil               False  b aɪ sil b aɪ sil   \n",
       "\n",
       "      fin_transcript                                all_fin_transcripts  \n",
       "0              g i l  [g i l, g i lː, g i rː, g æ l, g æ lː, g æ rː,...  \n",
       "1           h i l ou  [h i l ou, h i l u, h i l y, h i lː ou, h i lː...  \n",
       "2              b u k  [b u k, b u kː, b u p, b y k, b y kː, b y p, b...  \n",
       "3              l i n  [l i n, l i nː, l i rː, l æ n, l æ nː, l æ rː,...  \n",
       "4  b æe sil b æe sil  [b æe sil b æe sil, b æe sil b ɑe sil, b æe si...  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
